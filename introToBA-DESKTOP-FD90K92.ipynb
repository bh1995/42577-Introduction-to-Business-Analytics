{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preprocessing of the Database\n",
    "Since the provided dataset is not \"ready-to-use\", it needs to be handled so it could be used further safely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "df_or = pd.read_excel('Cities.xls', index_col=0, skipinitialspace=True) # Read with excel index. \n",
    "# Skip all white-spaces.\n",
    "\n",
    "df = df_or.set_index('cityID') # Remove the indices and use cityID as index.\n",
    "\n",
    "# Drop unnecessary columns (that explicitly imply each other)\n",
    "# cityID implies City, and Country\n",
    "# clusterID implies Typology\n",
    "# Pollution Index is restricted to be used in prediction.\n",
    "col2drop = ['Country', 'City', 'Typology', 'Pollution Index ']\n",
    "\n",
    "\n",
    "df.drop(columns=col2drop, inplace=True)# Typology <=> clusterID, City <=> cityID, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataframe shape [rows, columns]: (331, 73)\n",
      "3040\n"
     ]
    }
   ],
   "source": [
    "df = df.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "print(\"Initial dataframe shape [rows, columns]:\", df.shape)\n",
    "n_NaN = df.isna().sum().sum()\n",
    "print(n_NaN) # As you can see the total number of NaNs in the database 3199, so we need to impute.\n",
    "\n",
    "# Impute all NaNs over the database.\n",
    "\n",
    "df_int = df.select_dtypes(include='integer')\n",
    "df_float = df.select_dtypes(include='float')\n",
    "\n",
    "df_int = df_int.fillna(df.mode().iloc[0]) # Try using mean/mod for different columns.\n",
    "df_float = df_float.fillna(df.mean().iloc[0]) # Try using mean/mod for different columns.\n",
    "\n",
    "df[df_int.columns.values.tolist()] = df_int # Use mod for integers,\n",
    "df[df_float.columns.values.tolist()] = df_float # Use mean for floats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataframe shape [rows, columns]: (331, 73)\n",
      "Current total NaN values: 3040\n"
     ]
    }
   ],
   "source": [
    "# Reseting dataset.\n",
    "df_or = pd.read_excel('FINAL-COMBINED-DATASET.xlsx', index_col=0, skipinitialspace=True) # Read with excel index. \n",
    "# Skip all white-spaces.\n",
    "df = df_or.set_index('cityID') # Remove the indices and use cityID as index.\n",
    "# df.info()\n",
    "# Drop unnecessary columns (that explicitly imply each other)\n",
    "# cityID implies City, and Country\n",
    "# clusterID implies Typology\n",
    "# Pollution Index is restricted to be used in prediction.\n",
    "col2drop = ['Country', 'Typology', 'Pollution Index ']\n",
    "df.drop(columns=col2drop, inplace=True)# Typology <=> clusterID, City <=> cityID, \n",
    "df = df.replace(r'^\\s*$', np.NaN, regex=True)\n",
    "print(\"Initial dataframe shape [rows, columns]:\", df.shape)\n",
    "n_NaN = df.isna().sum().sum()\n",
    "print(\"Current total NaN values:\", n_NaN) # As you can see the total number of NaNs in the database 3199, so we need to impute.\n",
    "# Impute all NaNs over the database.\n",
    "df_int = df.select_dtypes(include='integer')\n",
    "df_float = df.select_dtypes(include='float')\n",
    "# df.info() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info() # To see how many missing values each column has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If more than 1/3 of the values are missing the column is dropped. i.e. should be atleast 331*(2/3)=218 non-null values.\n",
    "# df2 = df.drop(['Car Modeshare (%)', 'Public Transit Modeshare (%)', 'Bicycle Modeshare (%)', 'Walking Modeshare (%)', 'Congestion (%)','Congestion AM Peak (%)','Congestion PM Peak (%)', 'Traffic Index', 'Travel Time Index', 'Inefficiency Index', 'Unemployment Rate (%)', 'Poverty Rate (%)', 'Safety Index'], axis=1)\n",
    "# df = df.drop(['Car Modeshare (%)', 'Car Modeshare (%)', 'Public Transit Modeshare (%)', 'Bicycle Modeshare (%)', 'Walking Modeshare (%)', 'Congestion (%)','Congestion AM Peak (%)','Congestion PM Peak (%)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def predict_missing_values(df):\n",
    "    \"\"\"\n",
    "    This function will take in the dataframe and for each column predict the missing values.\n",
    "    It also scales the dataframe before performing value predictions. \n",
    "    \"\"\"\n",
    "    # Find which columns are missing values and add the column names to list.\n",
    "    nan_values = df.isna()\n",
    "    nan_columns = nan_values.any()\n",
    "    nan_columns = df.columns[nan_columns].tolist()\n",
    "    # print(nan_columns)\n",
    "    # Normalize dataset\n",
    "#     x = df.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#     x_scaled = min_max_scaler.fit_transform(x)\n",
    "#     x_unscaled =  min_max_scaler.inverse_transform(x_scaled)\n",
    "#     df = pd.DataFrame(x_scaled)\n",
    "\n",
    "    for i in nan_columns:\n",
    "        test_df = df[df[i].isnull()]\n",
    "        # print(test_df)\n",
    "        df2 = df.dropna()\n",
    "        y_train = df2[i]\n",
    "        X_train = df2.drop(i, axis=1)\n",
    "        X_train_scaled = min_max_scaler.fit_transform(X_train.values)\n",
    "        X_train = pd.DataFrame(X_train_scaled)\n",
    "        \n",
    "        X_test = test_df.drop(i, axis=1)\n",
    "        X_test_scaled = min_max_scaler.fit_transform(X_test.values)\n",
    "        X_test = pd.DataFrame(X_test_scaled)\n",
    "        # Impute all NaNs over the database.\n",
    "        X_test_int = X_test.select_dtypes(include='integer')\n",
    "        X_test_float = X_test.select_dtypes(include='float')\n",
    "        X_test_int = X_test_int.fillna(X_test.mode().iloc[0]) # Try using mean/mod for different columns.\n",
    "        X_test_float = X_test_float.fillna(X_test.mean().iloc[0]) # Try using mean/mod for different columns.\n",
    "        X_test[X_test_int.columns.values.tolist()] = X_test_int # Use mod for integers,\n",
    "        X_test[X_test_float.columns.values.tolist()] = X_test_float # Use mean for floats\n",
    "        # print(\"Total nr. NaN values:\", X_test.isna().sum().sum())\n",
    "        # print(X_test)\n",
    "        \n",
    "        # Train model to fit dataset and predict missing values from column i\n",
    "        # lr = LinearRegression()\n",
    "        # lr.fit(X_train, y_train)\n",
    "        # y_pred = lr.predict(X_test)\n",
    "        rfr = RandomForestRegressor(n_estimators = 1000, max_depth = 1000, random_state = 42)\n",
    "        rfr.fit(X_train, y_train)\n",
    "        y_pred = rfr.predict(X_test)\n",
    "        # print(y_pred)\n",
    "        #replace the missing values with predicted values\n",
    "        df.loc[df[i].isnull(), i] = y_pred\n",
    "        \n",
    "        # print(\"Done with column\", i)\n",
    "    #df['CO2 Emissions per Capita (metric tonnes)'] = df_targets # Add the original targets back at the end.\n",
    "    assert df.isna().sum().sum() == 0, \"ERROR!, There still contains NaN values in the DataFrame\" \n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:375: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\bjorn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:376: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe after predicting missing values: (331, 73)\n",
      "nr NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "df = predict_missing_values(df)\n",
    "print(\"Shape of dataframe after predicting missing values:\", df.shape)\n",
    "print(\"nr NaN values:\", df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the database:\n",
    "\n",
    "# df_train = df.iloc[0:tr_slice_ind]\n",
    "# df_test = df.iloc[tr_slice_ind::]\n",
    "\n",
    "\n",
    "\n",
    "# tr_mean = tr_inputs.mean() # min/max normalization\n",
    "# tr_min_ = tr_inputs.min()\n",
    "# tr_max_ = tr_inputs.max()\n",
    "\n",
    "# tr_inputs = (tr_inputs-tr_mean)/(tr_max_-tr_min_)\n",
    "\n",
    "df_targets = df['CO2 Emissions per Capita (metric tonnes)']\n",
    "df_inputs = df.drop(columns=['CO2 Emissions per Capita (metric tonnes)'])\n",
    "\n",
    "# df_in_mean = df_inputs.mean()\n",
    "# df_in_min = df_inputs.min()\n",
    "# df_in_max = df_inputs.max()\n",
    "\n",
    "# df_in = (df_inputs - df_in_mean)/(df_in_max - df_in_min)\n",
    "\n",
    "train_perc = 0.75\n",
    "tr_slice_ind = int(len(df)*0.75)+1\n",
    "\n",
    "tr_target = df_targets[0:tr_slice_ind]\n",
    "tr_inputs = df_in.iloc[0:tr_slice_ind]\n",
    "\n",
    "ts_target = df_targets[tr_slice_ind::]\n",
    "ts_inputs = df_in.iloc[tr_slice_ind::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 18)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "# print(p_df.head())\n",
    "# len(pca.components_)\n",
    "pca.fit(tr_inputs)\n",
    "expl=pca.explained_variance_ratio_\n",
    "cdf=[sum(expl[:i+1]) for i in range(len(expl))]\n",
    "plt.plot(range(len(expl)), cdf);\n",
    "# print(cdf[:15]) # 15 most explaining components\n",
    "pca = PCA(n_components=18) # Looks to about how many components explains 95% of the total variance.\n",
    "comps = pca.fit_transform(tr_inputs)\n",
    "p_df = pd.DataFrame(comps)\n",
    "p_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8368883048989924"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 20)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [3, 5, 8]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "\n",
    "regr = RandomForestRegressor()\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "regr = RandomizedSearchCV(estimator = regr, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "clf = MLPRegressor(hidden_layer_sizes=(8, 32, 16), \n",
    "                   activation='relu',\n",
    "                   solver = 'adam',\n",
    "                   alpha = 1e-1,\n",
    "                   learning_rate='adaptive',\n",
    "                   learning_rate_init=2.25e-5,\n",
    "                   max_iter=35000,\n",
    "                   random_state = 42,\n",
    "                   shuffle=False).fit(p_df, tr_target)\n",
    "\n",
    "pca_test = pca.transform(ts_inputs)\n",
    "p_test = pd.DataFrame(pca_test)\n",
    "\n",
    "est_out = clf.predict(p_test)\n",
    "\n",
    "R_2 = r2_score(ts_target, est_out)\n",
    "\n",
    "R_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (i, _) in df.iteritems():\n",
    "#     print(df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 59)\n",
      "R2 score: -1.0501041615581932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pca_test = pca.transform(ts_inputs)\n",
    "p_test = pd.DataFrame(pca_test)\n",
    "# print(p_test.shape)\n",
    "model_SVR = SVR(C=1.0, epsilon=0.2)\n",
    "print(tr_inputs.shape)\n",
    "model_SVR.fit(p_df, tr_target)\n",
    "est_out_svm = model_SVR.predict(p_test)\n",
    "print(\"R2 score:\", r2_score(ts_target, est_out_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9.596514032859412\n",
      "mean and std of targets: 11.911943928439022 6.702325862171413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(ts_target, est_out_svm))\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"mean and std of targets:\", np.mean(ts_target), np.std(ts_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.32528564,  4.05967819,  4.49630203,  0.35575135,  8.6546077 ,\n",
       "        9.56696068,  5.46667222, 13.6009818 ,  5.09078199, 14.21014084,\n",
       "       12.6127393 ,  8.22381067,  0.95308453,  0.07004595,  2.46690822,\n",
       "        4.69181838,  6.90212741,  6.65772994,  1.51314104,  3.94625506,\n",
       "        4.25998179,  5.5576448 ,  7.54116421,  8.2791104 ,  5.13337423,\n",
       "       10.06643835,  0.36929052,  0.30436386,  6.49031033,  7.18900378,\n",
       "       10.35428745,  1.31178904,  4.14051446,  5.5428264 ,  1.42807879,\n",
       "        3.138044  ,  1.18091641,  3.8412604 ,  0.87986978,  6.0743555 ,\n",
       "        5.65457358,  3.02560062,  6.9236103 ,  7.69119088,  0.95383838,\n",
       "        4.93554685,  7.34172287,  2.00114289,  8.59882033,  5.94126175,\n",
       "        0.21454983,  4.6042168 , 12.36930708,  5.9786258 ,  4.20326899,\n",
       "        7.10793801,  4.9686041 ,  3.42034457,  2.81751902,  0.56111396,\n",
       "        2.21001742,  8.01800757, 12.64253499,  0.8148062 ,  6.05788835,\n",
       "        9.17470417,  7.55835965,  5.30953793,  5.39060814, 13.94373507,\n",
       "       12.00035302,  1.80974311,  8.24508158,  0.70866813,  5.25240146,\n",
       "        4.95223301,  7.03833424,  4.30988534,  0.5551503 ,  3.69614191,\n",
       "        4.85854215,  3.68068708])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_out_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.1,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (8, 32, 16),\n",
       " 'learning_rate': 'adaptive',\n",
       " 'learning_rate_init': 2.25e-05,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 35000,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 42,\n",
       " 'shuffle': False,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
